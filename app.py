# pages/2_Analysis.py
import io
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import shapiro, ttest_ind, mannwhitneyu, chi2_contingency
import statsmodels.formula.api as smf
import seaborn as sns

st.set_page_config(page_title="NHANES Analysis", layout="wide")
st.title("NHANES Pre vs Post â€“ Final Analiz")

# ---------------------------
# 1. HARÄ°TALAMA
# ---------------------------
RENAME_MAP = {
    # --- KÄ°MLÄ°K & AÄIRLIK ---
    "SEQN": "ID", "WTPH2YR": "WEIGHT_LAB",
    # --- DEMOGRAFÄ° ---
    "RIDAGEYR": "AGE", "RIAGENDR": "SEX", "RIDRETH3": "RACE",
    "INDFMPIR": "PIR", "PERIOD": "PERIOD",
    # --- VÃœCUT Ã–LÃ‡ÃœMLERÄ° ---
    "BMXWT": "WEIGHT_KG", "BMXHT": "HEIGHT_CM", "BMXBMI": "BMI",
    "BMXWAIST": "WAIST_CM", "BMXHIP": "HIP_CM",
    # --- SÄ°GARA DEÄÄ°ÅKENLERÄ° ---
    "SMQ020": "SMOKE_LIFE_100",   
    "SMQ040": "SMOKE_NOW",        
    "SMD030": "AGE_STARTED",      
    "SMD650": "CIGS_PER_DAY_NOW", 
    "SMD057": "CIGS_PER_DAY_QUIT",
    "SMQ050Q": "TIME_SINCE_QUIT", 
    "SMQ050U": "UNIT_SINCE_QUIT", 
    "SMD630": "AGE_FIRST_CIG",    
    # --- LAB DEÄERLERÄ° ---
    "LBXWBCSI": "WBC", "LBXLYPCT": "LYMPH_PCT", "LBXMOPCT": "MONO_PCT",
    "LBXNEPCT": "NEUT_PCT", "LBXEOPCT": "EOS_PCT", "LBXBAPCT": "BASO_PCT",
    "LBDLYMNO": "LYMPH_ABS", "LBDMONO": "MONO_ABS", "LBDNENO": "NEUT_ABS",
    "LBDEONO": "EOS_ABS", "LBDBANO": "BASO_ABS",
    "LBXRBCSI": "RBC", "LBXHGB": "HGB", "LBXHCT": "HCT", "LBXMCVSI": "MCV",
    "LBXMC": "MCHC", "LBXMCHSI": "MCH", "LBXRDW": "RDW", "LBXPLTSI": "PLT",
    "LBXMPSI": "MPV", "LBXNRBC": "NRBC", "LBXCRP": "CRP",
}

# ---------------------------
# HELPERS
# ---------------------------
def robust_read_csv(uploaded_file):
    for enc in ["utf-8-sig", "utf-8", "cp1254", "latin1"]:
        try:
            return pd.read_csv(uploaded_file, encoding=enc)
        except Exception:
            uploaded_file.seek(0)
            continue
    raise ValueError("CSV okunamadÄ±.")

def ensure_upper_cols(df):
    df = df.copy()
    df.columns = [str(c).strip().upper() for c in df.columns]
    return df

def p_label_detailed(p):
    if not np.isfinite(p): return "NA"
    if p < 0.001: return "<0.001"
    if p < 0.01: return "<0.01"
    if p < 0.05: return "<0.05"
    return f"{p:.3f}"

def check_normality(data):
    try:
        data = np.asarray(data, dtype=float)
        data = data[np.isfinite(data)]
        if len(data) < 3: return np.nan
        _, p = shapiro(data)
        return p
    except: return np.nan

def mean_sd(series):
    s = pd.to_numeric(series, errors="coerce").dropna()
    if s.empty: return np.nan, np.nan
    return float(s.mean()), float(s.std())

def median_iqr(series):
    s = pd.to_numeric(series, errors="coerce").dropna()
    if s.empty: return np.nan, np.nan, np.nan
    return float(s.median()), float(s.quantile(0.25)), float(s.quantile(0.75))

def format_val_disp(val, q1_sd, q3_sd, is_parametric):
    if np.isfinite(val):
        if is_parametric: return f"{val:.2f} Â± {q1_sd:.2f}" 
        else: return f"{val:.3g} [{q1_sd:.3g}â€“{q3_sd:.3g}]"
    return "NA"

# --- CLIFF'S DELTA ---
def cliffs_delta(x, y):
    """Effect size calculation for non-parametric data."""
    x = pd.to_numeric(x, errors='coerce').dropna().values
    y = pd.to_numeric(y, errors='coerce').dropna().values
    if len(x) == 0 or len(y) == 0: return np.nan
    
    if len(x) * len(y) > 1_000_000:
        np.random.seed(42)
        x = np.random.choice(x, min(len(x), 1000), replace=False)
        y = np.random.choice(y, min(len(y), 1000), replace=False)
        
    m, n = len(x), len(y)
    count = 0
    for i in x:
        count += np.sum(i > y) - np.sum(i < y)
    return count / (m * n)

# ---------------------------
# HESAPLAMA MOTORU
# ---------------------------
def compute_indices(df):
    out = df.copy()
    # ==========================================
    # â¬‡ï¸ BURAYA YAPIÅTIRIN (TANSÄ°YON HESABI) â¬‡ï¸
    # ==========================================
    
    # 0. TANSÄ°YON VE NABIZ ORTALAMALARI (Yeni Ekleme)
    # Ã–nce sÃ¼tunlarÄ±n veride olup olmadÄ±ÄŸÄ±nÄ± kontrol edip sayÄ±ya Ã§evirelim
    bp_cols = ['BPXOSY2', 'BPXOSY3', 'BPXODI2', 'BPXODI3', 'BPXOPLS2', 'BPXOPLS3']
    for col in bp_cols:
        if col in out.columns:
            out[col] = pd.to_numeric(out[col], errors='coerce')

    # OrtalamalarÄ± Hesaplama (Varsa hesapla, yoksa NaN bÄ±rak)
    if 'BPXOSY2' in out.columns and 'BPXOSY3' in out.columns:
        out['SYSTOLICBP'] = out[['BPXOSY2', 'BPXOSY3']].mean(axis=1, skipna=True)
    
    if 'BPXODI2' in out.columns and 'BPXODI3' in out.columns:
        out['DIASTOLICBP'] = out[['BPXODI2', 'BPXODI3']].mean(axis=1, skipna=True)
        
    if 'BPXOPLS2' in out.columns and 'BPXOPLS3' in out.columns:
        out['PULSEAVG'] = out[['BPXOPLS2', 'BPXOPLS3']].mean(axis=1, skipna=True)
    
    # 1. SayÄ±sal DÃ¶nÃ¼ÅŸÃ¼m
    cols_to_numeric = [
        "NEUT_ABS", "LYMPH_ABS", "MONO_ABS", "PLT", "WBC", "CRP",
        "AGE", "AGE_STARTED", "AGE_FIRST_CIG", "CIGS_PER_DAY_NOW", "SMOKE_LIFE_100", "SMOKE_NOW"
    ]
    for c in cols_to_numeric:
        if c in out.columns:
            out[c] = pd.to_numeric(out[c], errors="coerce")

    # 2. Ä°ndeksler
    # Mevcutlar:
        # NLR
    if "NEUT_ABS" in out.columns and "LYMPH_ABS" in out.columns:
        out["NLR"] = out["NEUT_ABS"] / out["LYMPH_ABS"]
        
        # dNLR (Derived NLR) -> FormÃ¼l: NÃ¶trofil / (WBC - NÃ¶trofil)
        if "WBC" in out.columns:
             # PaydanÄ±n 0 olmasÄ±nÄ± engellemek iÃ§in kÃ¼Ã§Ã¼k bir gÃ¼venlik Ã¶nlemi alÄ±nabilir ama genelde gerekmez.
             denom = out["WBC"] - out["NEUT_ABS"]
             out["dNLR"] = out["NEUT_ABS"] / denom
        
        # SII ve PLR
        if "PLT" in out.columns:
            out["SII"] = (out["PLT"] * out["NEUT_ABS"]) / out["LYMPH_ABS"]
            out["PLR"] = out["PLT"] / out["LYMPH_ABS"]
        # SIRI
        if "MONO_ABS" in out.columns:
            out["SIRI"] = (out["NEUT_ABS"] * out["MONO_ABS"]) / out["LYMPH_ABS"]
            
            # MLR (Monocyte to Lymphocyte Ratio)
            out["MLR"] = out["MONO_ABS"] / out["LYMPH_ABS"]
            
            # NMLR (Neutrophil + Monocyte to Lymphocyte Ratio)
            # Not: EÄŸer kastettiÄŸiniz sadece NÃ¶trofil/Monosit ise formÃ¼lÃ¼: out["NEUT_ABS"] / out["MONO_ABS"] yapÄ±n.
            out["NMLR"] = (out["NEUT_ABS"] + out["MONO_ABS"]) / out["LYMPH_ABS"]

            # AISI
            if "PLT" in out.columns:
                out["AISI"] = (out["NEUT_ABS"] * out["PLT"] * out["MONO_ABS"]) / out["LYMPH_ABS"]

    # 3. SÄ°GARA (3 KATEGORÄ°)
    out["SMOKING_STATUS"] = np.nan
    if "SMOKE_LIFE_100" in out.columns and "SMOKE_NOW" in out.columns:
        s100 = out["SMOKE_LIFE_100"]
        snow = out["SMOKE_NOW"]
        out.loc[s100 == 2, "SMOKING_STATUS"] = "Never Smoker"
        out.loc[(s100 == 1) & (snow == 3), "SMOKING_STATUS"] = "Former Smoker"
        out.loc[(s100 == 1) & (snow.isin([1, 2])), "SMOKING_STATUS"] = "Current Smoker"

    # 4. PACK-YEARS
    out["PACK_YEARS"] = np.nan 
    out.loc[out["SMOKING_STATUS"] == "Never Smoker", "PACK_YEARS"] = 0.0
    
    if "AGE" in out.columns and "CIGS_PER_DAY_NOW" in out.columns:
        age = out["AGE"]
        cigs = out["CIGS_PER_DAY_NOW"].replace({999: np.nan, 777: np.nan})
        
        # BaÅŸlama YaÅŸÄ± (Yedekli)
        start = pd.Series(np.nan, index=out.index)
        if "AGE_STARTED" in out.columns: start = start.fillna(out["AGE_STARTED"])
        if "AGE_FIRST_CIG" in out.columns: start = start.fillna(out["AGE_FIRST_CIG"])
        start = start.replace({999: np.nan, 777: np.nan})
        
        years = (age - start).clip(lower=0)
        py = (cigs / 20) * years
        
        mask = (out["SMOKING_STATUS"] == "Current Smoker")
        out.loc[mask, "PACK_YEARS"] = py[mask]
    # ==========================================
    # â¬‡ï¸ IRK ETÄ°KETLEME (BURAYA YAPIÅTIRIN) â¬‡ï¸
    # ==========================================
    if "RACE" in out.columns:
        # NHANES RIDRETH3 KodlarÄ±
        race_mapping = {
            1: "Mexican American",
            2: "Other Hispanic",
            3: "Non-Hispanic White",
            4: "Non-Hispanic Black",
            6: "Non-Hispanic Asian",
            7: "Other/Multi-Racial"
        }
        # Sadece sÃ¼tun sayÄ±sal ise Ã§evir (Hata almamak iÃ§in)
        if pd.api.types.is_numeric_dtype(out["RACE"]):
             out["RACE"] = out["RACE"].map(race_mapping)

    return out

# ---------------------------
# UI: YÃ¼kleme
# ---------------------------
col1, col2 = st.columns(2)
pre_file = col1.file_uploader("Pre CSV", key="pre")
post_file = col2.file_uploader("Post CSV", key="post")

if not pre_file or not post_file:
    st.info("DosyalarÄ± yÃ¼kleyin.")
    st.stop()

pre = ensure_upper_cols(robust_read_csv(pre_file)).rename(columns=RENAME_MAP)
post = ensure_upper_cols(robust_read_csv(post_file)).rename(columns=RENAME_MAP)

pre["PERIOD"] = "Pre"
post["PERIOD"] = "Post"

pre = compute_indices(pre)
post = compute_indices(post)
df = pd.concat([pre, post], ignore_index=True)

# ---------------------------
# Sidebar: Filtreler ve SeÃ§imler
# ---------------------------
st.sidebar.title("Ayarlar")
page = st.sidebar.radio("Sayfa:", ["1. Ã–zet Tablo", "2. Grafikler", "3. Korelasyon", "4. Regresyon"])

st.sidebar.markdown("---")
if st.sidebar.checkbox("Sadece SII verisi olanlar", True):
    df_f = df.dropna(subset=["SII"]) if "SII" in df.columns else df
else:
    df_f = df

gender_filter = st.sidebar.radio("Cinsiyet:", ["TÃ¼mÃ¼", "KadÄ±n (2)", "Erkek (1)"])
if gender_filter == "KadÄ±n (2)": df_f = df_f[df_f["SEX"] == 2]
if gender_filter == "Erkek (1)": df_f = df_f[df_f["SEX"] == 1]

# DeÄŸiÅŸken SeÃ§imi
st.sidebar.markdown("---")
st.sidebar.subheader("DeÄŸiÅŸkenler")
default_vars = ["SII", "NLR", "dNLR", "PLR", "MLR", "NMLR", "SYSTOLICBP", "DIASTOLICBP", "PULSEAVG", "CRP", "WBC", "AGE", "BMI", "WAIST_CM", "SMOKING_STATUS"]
avail_vars = [c for c in default_vars if c in df_f.columns]
all_cols = sorted(list(df_f.columns))

# BURADA SEÃ‡Ä°LENLER 'vars_to_analyze' Ä°Ã‡Ä°NE GÄ°RER
vars_to_analyze = st.sidebar.multiselect("SeÃ§iniz:", all_cols, default=avail_vars)

# --- DÃœZELTÄ°LEN KISIM BAÅLANGICI ---
st.sidebar.info("ğŸ‘‡ SayÄ±sal gÃ¶rÃ¼nÃ¼p Kategorik olanlarÄ± seÃ§ (Ki-Kare iÃ§in)")
default_cats = ["SEX", "RACE", "SMOKING_STATUS"]
# Sadece ÅŸu an seÃ§ili olan deÄŸiÅŸkenlerin iÃ§inden varsayÄ±lanlarÄ± belirle!
valid_cat_defaults = [c for c in default_cats if c in vars_to_analyze]

forced_cat_vars = st.sidebar.multiselect("Kategorik Zorlama", vars_to_analyze, default=valid_cat_defaults)
# --- DÃœZELTÄ°LEN KISIM BÄ°TÄ°ÅÄ° ---

force_parametric = st.sidebar.checkbox("Parametrik Zorla (T-Test)", False)

pre_f = df_f[df_f["PERIOD"]=="Pre"]
post_f = df_f[df_f["PERIOD"]=="Post"]

# =========================================================
# SAYFA 1: Ã–ZET TABLO (SÄ°MGELÄ° ETKÄ° BÃœYÃœKLÃœKLERÄ°: d, e)
# =========================================================
if page == "1. Ã–zet Tablo":
    st.header("1. Ã–zet Ä°statistikler")
    
    rows = []
    posthoc_results = {}
    
    # --- TEST VE ETKÄ° SÄ°MGELERÄ° ---
    SYM_T = "áµƒ"       # T-Test
    SYM_MWU = "áµ‡"     # Mann-Whitney U
    SYM_CHI = "á¶œ"     # Chi-Square
    SYM_DELTA = "áµˆ"   # Cliff's Delta (SayÄ±sal)
    SYM_V = "áµ‰"       # Cramer's V (Kategorik - User isteÄŸi 'e')

    # --- YARDIMCI FONKSÄ°YONLAR ---
    def fmt_median_iqr(series):
        s = pd.to_numeric(series, errors="coerce").dropna()
        if s.empty: return "NA"
        med = s.median()
        q1 = s.quantile(0.25)
        q3 = s.quantile(0.75)
        return f"{med:.3g} [{q1:.3g}â€“{q3:.3g}]"

    def fmt_mean_sd(series):
        s = pd.to_numeric(series, errors="coerce").dropna()
        if s.empty: return "NA"
        m = s.mean()
        sd = s.std()
        return f"{m:.2f} Â± {sd:.2f}"

    def calculate_cramers_v(confusion_matrix):
        chi2 = chi2_contingency(confusion_matrix)[0]
        n = confusion_matrix.sum().sum()
        phi2 = chi2 / n
        r, k = confusion_matrix.shape
        phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))
        rcorr = r - ((r-1)**2)/(n-1)
        kcorr = k - ((k-1)**2)/(n-1)
        if min((kcorr-1), (rcorr-1)) == 0: return 0.0
        return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))

    for v in vars_to_analyze:
        pre_d = pre_f[v].dropna()
        post_d = post_f[v].dropna()
        
        if len(pre_d) < 2 or len(post_d) < 2: continue

        is_categorical = (v in forced_cat_vars) or (df_f[v].dtype == 'object')
        
        # ---------------------------------------------------------
        # A) KATEGORÄ°K (Cramer's V -> 'e')
        # ---------------------------------------------------------
        if is_categorical:
            ct = pd.crosstab(df_f[v], df_f["PERIOD"])
            if "Pre" in ct.columns and "Post" in ct.columns:
                chi2, p_overall, _, _ = chi2_contingency(ct)
                cramer_v = calculate_cramers_v(ct)
                
                # Simge 'e' eklendi
                effect_str = f"{cramer_v:.2f} {SYM_V}" 

                rows.append({
                    "Variable": v, 
                    "Pre (Ref)": f"N={ct['Pre'].sum()}", 
                    "Post": f"N={ct['Post'].sum()}", 
                    "P-Value": f"{p_label_detailed(p_overall)} {SYM_CHI}", 
                    "Effect Size": effect_str 
                })

                # Post-Hoc
                if ct.shape[0] > 2:
                    ph_rows = []
                    tot_pre = ct["Pre"].sum()
                    tot_post = ct["Post"].sum()
                    for cat in ct.index:
                        n1, n2 = ct.loc[cat, "Pre"], ct.loc[cat, "Post"]
                        r1, r2 = tot_pre - n1, tot_post - n2
                        sub_ct = np.array([[n1, n2], [r1, r2]])
                        _, p_sub, _, _ = chi2_contingency(sub_ct)
                        sub_cramer = calculate_cramers_v(pd.DataFrame(sub_ct))
                        
                        pc1 = (n1/tot_pre)*100
                        pc2 = (n2/tot_post)*100
                        
                        ph_rows.append({
                            "Subgroup": cat,
                            "Pre (Ref)": f"{n1} ({pc1:.1f}%)",
                            "Post": f"{n2} ({pc2:.1f}%)",
                            "P-Value": f"{p_label_detailed(p_sub)} {SYM_CHI}",
                            "Cramer's V": f"{sub_cramer:.2f}"
                        })
                    posthoc_results[v] = pd.DataFrame(ph_rows)

        # ---------------------------------------------------------
        # B) SAYISAL (Cliff's Delta -> 'd')
        # ---------------------------------------------------------
        else:
            pre_vals = pd.to_numeric(pre_d, errors="coerce")
            post_vals = pd.to_numeric(post_d, errors="coerce")
            
            p_norm = check_normality(pre_vals)
            is_norm = p_norm > 0.05 if np.isfinite(p_norm) else False
            use_para = force_parametric or is_norm
            
            delta_val = cliffs_delta(pre_vals, post_vals)
            val_str = f"{delta_val:.2f}" if np.isfinite(delta_val) else "NA"
            
            # Simge 'd' eklendi
            delta_str = f"{val_str} {SYM_DELTA}"
            
            if use_para:
                _, p = ttest_ind(pre_vals, post_vals, equal_var=False)
                d_pre = fmt_mean_sd(pre_vals)
                d_post = fmt_mean_sd(post_vals)
                test_sym = SYM_T
            else:
                _, p = mannwhitneyu(pre_vals, post_vals)
                d_pre = fmt_median_iqr(pre_vals)
                d_post = fmt_median_iqr(post_vals)
                test_sym = SYM_MWU
                
            rows.append({
                "Variable": v, 
                "Pre (Ref)": d_pre, 
                "Post": d_post,
                "P-Value": f"{p_label_detailed(p)} {test_sym}",
                "Effect Size": delta_str
            })
            
    if rows:
        st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)
        st.markdown("---")
        st.caption(f"""
        **Dipnotlar:**
        * **Ä°statistiksel Testler:** {SYM_T}: Welch T-Test, {SYM_MWU}: Mann-Whitney U, {SYM_CHI}: Ki-Kare.
        * **Etki BÃ¼yÃ¼klÃ¼ÄŸÃ¼ (Effect Size):** {SYM_DELTA}: Cliff's Delta (SayÄ±sal Veriler), {SYM_V}: Cramer's V (Kategorik Veriler).
        """)
    else:
        st.warning("Veri yok.")

    if posthoc_results:
        st.markdown("---")
        st.subheader("ğŸ” Kategorik Alt Analiz (Post-Hoc)")
        for k, v in posthoc_results.items():
            st.markdown(f"**{k} KÄ±rÄ±lÄ±mÄ±**")
            st.dataframe(v, use_container_width=True, hide_index=True)

    # ==============================================================================
    # â¬‡ï¸ SAYISAL ALT GRUP ANALÄ°ZÄ° (MEVCUT KODUNUZDA VARDI, KORUYORUZ) â¬‡ï¸
    # ==============================================================================
    st.markdown("---")
    st.subheader("ğŸ”¬ Alt Grup Analizi (Subgroup Analysis)")
    st.markdown("Bir sayÄ±sal deÄŸiÅŸkenin (Ã–rn: **SII**), belirli bir kategoriye (Ã–rn: **RACE**) gÃ¶re deÄŸiÅŸimini inceleyin.")

    numeric_opts = [c for c in vars_to_analyze if pd.api.types.is_numeric_dtype(df_f[c])]
    category_opts = [c for c in all_cols if (c in forced_cat_vars) or (df_f[c].dtype == 'object')]
    
    if numeric_opts and category_opts:
        col_sub1, col_sub2 = st.columns(2)
        with col_sub1:
            target_var = st.selectbox("1. SayÄ±sal DeÄŸiÅŸkeni SeÃ§ (Target):", numeric_opts, index=0)
        with col_sub2:
            def_idx = category_opts.index("RACE") if "RACE" in category_opts else 0
            group_var = st.selectbox("2. Kime GÃ¶re BakÄ±lsÄ±n? (Subgroup):", category_opts, index=def_idx)

        subgroup_rows = []
        # Mann-Whitney U simgesi
        SYM_MWU = "áµ‡"
        
        def fmt_median_iqr_sub(series):
            s = pd.to_numeric(series, errors="coerce").dropna()
            if s.empty: return "NA"
            med = s.median()
            q1 = s.quantile(0.25)
            q3 = s.quantile(0.75)
            return f"{med:.3g} [{q1:.3g}â€“{q3:.3g}]"
        
        unique_groups = sorted(df_f[group_var].dropna().unique())
        
        for grp in unique_groups:
            sub_df = df_f[df_f[group_var] == grp]
            pre_d = sub_df[sub_df["PERIOD"] == "Pre"][target_var].dropna()
            post_d = sub_df[sub_df["PERIOD"] == "Post"][target_var].dropna()
            
            if len(pre_d) < 2 or len(post_d) < 2: continue
            
            delta_val = cliffs_delta(pre_d, post_d)
            delta_str = f"{delta_val:.2f}" if np.isfinite(delta_val) else "NA"
            _, p = mannwhitneyu(pre_d, post_d)
            
            subgroup_rows.append({
                "Subgroup": grp,
                "Pre (Ref)": fmt_median_iqr_sub(pre_d),
                "Post": fmt_median_iqr_sub(post_d),
                "P-Value": f"{p_label_detailed(p)} {SYM_MWU}",
                "Cliff's Delta": delta_str
            })
            
        if subgroup_rows:
            st.markdown(f"**Analiz:** `{target_var}` deÄŸiÅŸkeninin `{group_var}` alt kÄ±rÄ±lÄ±mlarÄ±:")
            st.dataframe(pd.DataFrame(subgroup_rows), use_container_width=True, hide_index=True)
        else:
            st.warning("Veri yok.")
    else:
        st.info("Alt grup analizi iÃ§in seÃ§im yapÄ±nÄ±z.")
# =========================================================
# SAYFA 2: GRAFÄ°KLER (OUTLIER YÃ–NETÄ°MÄ° VE LOG SCALE EKLENDÄ°)
# =========================================================
elif page == "2. Grafikler":
    st.header("2. Grafikler (YayÄ±na HazÄ±rlÄ±k Modu)")

    # --- 1. DEÄÄ°ÅKEN SEÃ‡Ä°MÄ° ---
    plot_vars = st.multiselect(
        "Ã‡izilecek DeÄŸiÅŸkenleri SeÃ§in:", 
        vars_to_analyze, 
        default=vars_to_analyze[:min(4, len(vars_to_analyze))] if len(vars_to_analyze) > 0 else None
    )

    if plot_vars:
        # --- 2. GRAFÄ°K AYARLARI (EXPANDER) ---
        with st.expander("âš™ï¸ Grafik GÃ¶rÃ¼nÃ¼m & Ä°statistik AyarlarÄ±", expanded=True):
            tab1, tab2, tab3 = st.tabs(["ğŸ“Š Veri & Eksen", "ğŸ“ Ã‡izgi Stili", "ğŸ·ï¸ Etiketler"])
            
            with tab1:
                col_data1, col_data2 = st.columns(2)
                with col_data1:
                    st.markdown("##### ğŸ” Veri GÃ¶sterimi")
                    # Outlier Filtresi
                    remove_outliers = st.checkbox("AykÄ±rÄ± DeÄŸerleri Gizle (Outliers - IQR YÃ¶ntemi)", value=False, help="GrafiÄŸi bastÄ±ran Ã§ok yÃ¼ksek deÄŸerleri (Q3 + 1.5*IQR Ã¼zerini) gizler. Medyan farklarÄ±nÄ± gÃ¶rmek iÃ§in idealdir.")
                    # Log Scale
                    use_log = st.checkbox("Logaritmik Ã–lÃ§ek (Log Scale)", value=False, help="AÅŸÄ±rÄ± bÃ¼yÃ¼k ve kÃ¼Ã§Ã¼k deÄŸerleri aynÄ± grafikte dengeli gÃ¶sterir.")
                    
                    # Ä°statistik Tipi
                    plot_type = st.radio(
                        "Ä°statistiksel Ã–zet:", 
                        ["Ortalama Â± SD (Mean Â± SD)", "Medyan Â± IQR (Median Â± IQR)"],
                        horizontal=True
                    )
                with col_data2:
                    st.markdown("##### ğŸ¨ GÃ¶rÃ¼nÃ¼m")
                    cols_num = st.slider("Yan Yana Grafik", 1, 4, 2)
                    dot_size = st.slider("Nokta BÃ¼yÃ¼klÃ¼ÄŸÃ¼", 1, 15, 4)
                    c1 = st.color_picker("Pre Rengi", "#4c72b0")
                    c2 = st.color_picker("Post Rengi", "#c44e52")

            with tab2:
                st.markdown("##### Hata Ã‡ubuklarÄ± (Error Bars)")
                col_err1, col_err2, col_err3 = st.columns(3)
                with col_err1:
                    err_linewidth = st.slider("Ã‡izgi KalÄ±nlÄ±ÄŸÄ±", 0.5, 5.0, 1.5)
                with col_err2:
                    err_capsize = st.slider("Åapka GeniÅŸliÄŸi", 0, 20, 8)
                with col_err3:
                    err_capthick = st.slider("Åapka KalÄ±nlÄ±ÄŸÄ±", 0.5, 5.0, 1.5)

            with tab3:
                st.info("Tek deÄŸiÅŸken seÃ§iliyse baÅŸlÄ±klarÄ± Ã¶zelleÅŸtirebilirsiniz.")
                custom_title = st.text_input("Grafik BaÅŸlÄ±ÄŸÄ±", value="")
                col_lbl1, col_lbl2 = st.columns(2)
                with col_lbl1: custom_xlabel = st.text_input("X Ekseni", value="Grup")
                with col_lbl2: custom_ylabel = st.text_input("Y Ekseni", value=plot_vars[0] if len(plot_vars)==1 else "DeÄŸer")

        is_parametric_plot = "Ortalama" in plot_type
        
        # --- 3. Ã‡Ä°ZÄ°M MOTORU ---
        rows_num = int(np.ceil(len(plot_vars) / cols_num))
        fig_width = 5 * cols_num
        fig_height = 5 * rows_num
        fig, axes = plt.subplots(rows_num, cols_num, figsize=(fig_width, fig_height))
        
        if isinstance(axes, np.ndarray): axes = axes.flatten()
        else: axes = [axes]
        
        custom_palette = {"Pre": c1, "Post": c2}

        for i, v in enumerate(plot_vars):
            ax = axes[i]
            
            # --- OUTLIER FÄ°LTRELEME (Sadece Grafik Ä°Ã§in) ---
            # Orijinal df_f bozulmaz, plot_data geÃ§ici oluÅŸturulur
            plot_data = df_f.copy()
            
            if remove_outliers and pd.api.types.is_numeric_dtype(plot_data[v]):
                Q1 = plot_data[v].quantile(0.25)
                Q3 = plot_data[v].quantile(0.75)
                IQR = Q3 - Q1
                upper_limit = Q3 + 1.5 * IQR
                # Alt limit genelde biyolojik veride 0'dÄ±r ama yine de yazalÄ±m
                lower_limit = Q1 - 1.5 * IQR
                
                # Filtrele
                plot_data = plot_data[(plot_data[v] <= upper_limit) & (plot_data[v] >= lower_limit)]
                
                # KaÃ§ veri atÄ±ldÄ±ÄŸÄ±nÄ± konsola veya baÅŸlÄ±ÄŸa yazabiliriz (Opsiyonel)
                # st.write(f"{v}: {len(df_f) - len(plot_data)} aykÄ±rÄ± deÄŸer gizlendi.")

            # Kategorik kontrolÃ¼
            is_categorical = (v in forced_cat_vars) or (plot_data[v].dtype == 'object')
            
            if is_categorical:
                counts = plot_data.groupby(["PERIOD", v]).size().reset_index(name="Count")
                sns.barplot(data=counts, x="PERIOD", y="Count", hue=v, ax=ax, palette="Set2")
                ax.set_title(f"{v} DaÄŸÄ±lÄ±mÄ±")
            else:
                # --- DOT PLOT ---
                sns.stripplot(
                    data=plot_data, x="PERIOD", y=v, 
                    palette=custom_palette, 
                    alpha=0.6,    
                    size=dot_size, 
                    jitter=0.25,   
                    ax=ax,
                    zorder=0      
                )

                # --- Ä°STATÄ°STÄ°K HESABI ---
                periods = ["Pre", "Post"]
                for j, period in enumerate(periods):
                    subset = plot_data[plot_data["PERIOD"] == period][v].dropna()
                    if len(subset) == 0: continue

                    if is_parametric_plot:
                        center = subset.mean()
                        spread = subset.std()
                        yerr = spread 
                    else:
                        center = subset.median()
                        q1 = subset.quantile(0.25)
                        q3 = subset.quantile(0.75)
                        yerr = [[center - q1], [q3 - center]] 
                    
                    # Error Bar
                    ax.errorbar(
                        x=j, y=center, yerr=yerr, 
                        fmt='none', ecolor='black', 
                        elinewidth=err_linewidth, capsize=err_capsize, capthick=err_capthick, 
                        zorder=5
                    )
                    # Mean/Median Line
                    ax.hlines(
                        y=center, xmin=j-0.2, xmax=j+0.2, 
                        colors='black', linewidth=err_linewidth + 0.5, zorder=6
                    )

                # --- LOG SCALE AYARI ---
                if use_log:
                    ax.set_yscale('log')
                    # Logaritmik skalada 0 hatasÄ± olmasÄ±n diye minik bir deÄŸer ekleme gerekebilir
                    # ama Seaborn genelde bunu handle eder. Ederse de etiketleri dÃ¼zeltelim:
                    from matplotlib.ticker import ScalarFormatter
                    ax.yaxis.set_major_formatter(ScalarFormatter())

            # --- ETÄ°KETLER ---
            if len(plot_vars) == 1:
                ax.set_title(custom_title if custom_title else v, fontweight="bold", fontsize=14)
                ax.set_xlabel(custom_xlabel, fontsize=12, fontweight="bold")
                ax.set_ylabel(custom_ylabel, fontsize=12, fontweight="bold")
            else:
                ax.set_title(v, fontweight="bold")
                ax.set_xlabel("")

            # Temizlik
            ax.grid(axis='y', linestyle='--', alpha=0.3, which='both') # Log iÃ§in 'both'
            ax.spines['top'].set_visible(False)
            ax.spines['right'].set_visible(False)
            ax.spines['left'].set_linewidth(1.5)
            ax.spines['bottom'].set_linewidth(1.5)

        for j in range(i+1, len(axes)): fig.delaxes(axes[j])
        plt.tight_layout()
        st.pyplot(fig)

        # Ä°ndirme
        st.markdown("---")
        col_d1, col_d2 = st.columns([3, 1])
        with col_d2:
            import io
            buf = io.BytesIO()
            fig.savefig(buf, format="png", dpi=300, bbox_inches='tight', transparent=True)
            st.download_button("ğŸ“¥ GrafiÄŸi Ä°ndir (300 DPI)", buf.getvalue(), "grafik.png", "image/png", use_container_width=True)
    else:
        st.info("LÃ¼tfen soldan veya yukarÄ±dan en az bir deÄŸiÅŸken seÃ§in.")
# =========================================================
# SAYFA 3: KORELASYON (GELÄ°ÅMÄ°Å HEATMAP EDÄ°TÃ–RÃœ)
# =========================================================
elif page == "3. Korelasyon":
    st.header("3. Korelasyon Analizi (Heatmap)")

    # 1. Sadece SayÄ±sal DeÄŸiÅŸkenleri SeÃ§
    num_cols = [c for c in vars_to_analyze if pd.api.types.is_numeric_dtype(df_f[c]) and c not in forced_cat_vars]

    if len(num_cols) < 2:
        st.warning("âš ï¸ Korelasyon analizi yapabilmek iÃ§in sol taraftan en az 2 adet sayÄ±sal deÄŸiÅŸken seÃ§melisiniz.")
    else:
        # --- AYARLAR MENÃœSÃœ ---
        with st.expander("âš™ï¸ Korelasyon ve GÃ¶rÃ¼nÃ¼m AyarlarÄ±", expanded=True):
            tab1, tab2 = st.tabs(["ğŸ“Š Analiz & Stil", "ğŸ“ Boyutlar"])
            
            with tab1:
                col_c1, col_c2, col_c3 = st.columns(3)
                with col_c1:
                    corr_method = st.selectbox("YÃ¶ntem", ["spearman", "pearson", "kendall"], help="Normal daÄŸÄ±lÄ±m yoksa Spearman Ã¶nerilir.")
                    mask_upper = st.checkbox("Ãœst ÃœÃ§geni Gizle (Mask Upper)", value=True, help="Simetrik tekrarÄ± Ã¶nler, daha sade gÃ¶rÃ¼nÃ¼r.")
                with col_c2:
                    cmap_choice = st.selectbox("Renk Paleti", ["coolwarm", "RdBu_r", "viridis", "magma", "seismic", "icefire"], index=0)
                    show_annot = st.checkbox("DeÄŸerleri GÃ¶ster", value=True)
                with col_c3:
                    annot_font_size = st.slider("YazÄ± Puntosu (Font Size)", 6, 24, 10)
                    decimals = st.slider("OndalÄ±k Basamak", 1, 4, 2)

            with tab2:
                col_d1, col_d2 = st.columns(2)
                with col_d1:
                    fig_width = st.slider("Grafik GeniÅŸliÄŸi", 6, 30, 12)
                with col_d2:
                    fig_height = st.slider("Grafik YÃ¼ksekliÄŸi", 6, 30, 10)

        # --- HESAPLAMA ---
        corr_matrix = df_f[num_cols].corr(method=corr_method)

        # --- Ã‡Ä°ZÄ°M ---
        fig, ax = plt.subplots(figsize=(fig_width, fig_height))
        
        # Maskeleme (Ãœst Ã¼Ã§geni beyaz yap)
        mask = None
        if mask_upper:
            mask = np.triu(np.ones_like(corr_matrix, dtype=bool))

        sns.heatmap(
            corr_matrix, 
            annot=show_annot,           # DeÄŸerleri yaz/yazma
            fmt=f".{decimals}f",        # VirgÃ¼lden sonra kaÃ§ basamak
            cmap=cmap_choice,           # Renk paketi
            ax=ax, 
            mask=mask,                  # Ãœst Ã¼Ã§gen maskesi
            annot_kws={"size": annot_font_size, "weight": "bold"}, # YazÄ± boyutu ve kalÄ±nlÄ±ÄŸÄ±
            linewidths=1,               # Kutular arasÄ± beyaz Ã§izgi kalÄ±nlÄ±ÄŸÄ±
            linecolor='white',
            cbar_kws={"shrink": 0.8},   # Renk barÄ±nÄ±n boyutu
            square=True,                 # KutularÄ± kare yap
            vmin=-1, vmax=1             # Renk skalasÄ±nÄ± -1 ile +1 arasÄ±na sabitle
        )
        
        # Eksen YazÄ±larÄ±nÄ± DÃ¼zelt
        plt.xticks(rotation=45, ha='right', fontsize=annot_font_size + 2)
        plt.yticks(rotation=0, fontsize=annot_font_size + 2)
        
        plt.title(f"{corr_method.capitalize()} Correlation Matrix", fontsize=annot_font_size + 4, fontweight='bold', pad=20)
        plt.tight_layout()
        st.pyplot(fig)

        # --- Ä°NDÄ°RME ---
        st.markdown("---")
        col_down1, col_down2 = st.columns([3, 1])
        with col_down2:
            import io
            buf = io.BytesIO()
            fig.savefig(buf, format="png", dpi=300, bbox_inches='tight', transparent=True)
            st.download_button(
                label="ğŸ“¥ Heatmap Ä°ndir (300 DPI)",
                data=buf.getvalue(),
                file_name=f"correlation_heatmap_{corr_method}.png",
                mime="image/png",
                use_container_width=True
            )

# =========================================================
# SAYFA 4: KOMPAKT Ã‡OKLU REGRESYON (STANDARDIZE GÃ–RSEL SEÃ‡ENEÄÄ°)
# =========================================================
elif page == "4. Regresyon":
    st.header("4. Ã‡oklu Regresyon Ã–zeti (Compact Summary)")
    st.markdown("""
    Bu modÃ¼l, seÃ§ilen tÃ¼m parametreler (SII, NLR, PLR vb.) iÃ§in ayrÄ± ayrÄ± regresyon modeli kurar.
    KarmaÅŸayÄ± Ã¶nlemek iÃ§in sadece **Ana FaktÃ¶rÃ¼n** (Ã–rn: PERIOD) etkisini raporlar.
    """)
    
    st.markdown("---")
    
    # 1. DEÄÄ°ÅKEN SEÃ‡Ä°MÄ°
    numeric_candidates = df_f.select_dtypes(include=np.number).columns.tolist()
    
    # A) TARGETS
    defaults = [c for c in ["SII", "NLR", "PLR", "dNLR", "CRP"] if c in numeric_candidates]
    targets = st.multiselect("1. Analiz Edilecek Parametreler (SatÄ±rlar):", 
                             numeric_candidates, default=defaults)
    
    # B) ANA FAKTÃ–R
    remaining = [c for c in all_cols if c not in targets]
    main_factor_def = remaining.index("PERIOD") if "PERIOD" in remaining else 0
    main_factor = st.selectbox("2. Ana FaktÃ¶r (Grup/DÃ¶nem):", remaining, index=main_factor_def)
    
    # C) CONFOUNDERS
    std_confounders = ["AGE", "SEX", "BMI", "RACE", "SMOKING_STATUS"]
    avail_conf = [c for c in std_confounders if c in df_f.columns and c not in targets and c != main_factor]
    
    confounders = st.multiselect("3. DÃ¼zeltme FaktÃ¶rleri (Adjusted for):", 
                                 options=[c for c in remaining if c != main_factor],
                                 default=avail_conf)
    
    st.markdown("---")

    if st.button("Tablo ve GrafiÄŸi OluÅŸtur"):
        if not targets:
            st.warning("LÃ¼tfen en az bir parametre seÃ§in.")
        else:
            summary_data = []
            predictors = [main_factor] + confounders
            progress_bar = st.progress(0)
            
            for i, target_var in enumerate(targets):
                progress_bar.progress((i + 1) / len(targets))
                
                # Model Verisi
                cols = [target_var] + predictors
                model_data = df_f[cols].dropna()
                
                if len(model_data) < 50: continue

                # Standart Sapma (GÃ¶rsel DÃ¼zeltme Ä°Ã§in LazÄ±m Olacak)
                target_std = model_data[target_var].std()

                # Model Kurulumu
                formula = f"{target_var} ~ {' + '.join(predictors)}"
                model = smf.ols(formula, data=model_data).fit()
                
                # Hedef KatsayÄ±yÄ± Bul
                target_coef_name = None
                for name in model.params.index:
                    if main_factor in name and name != "Intercept":
                        target_coef_name = name
                        break
                
                if target_coef_name:
                    coef = model.params[target_coef_name]
                    conf = model.conf_int().loc[target_coef_name]
                    p_val = model.pvalues[target_coef_name]
                    
                    p_str = "<0.001" if p_val < 0.001 else f"{p_val:.3f}"
                    
                    summary_data.append({
                        "Parametre": target_var,
                        "Adjusted Beta (Grup)": f"{coef:.2f}",
                        "%95 GA": f"{conf[0]:.2f} â€“ {conf[1]:.2f}",
                        "p": p_str,
                        # Gizli veriler (Grafik iÃ§in)
                        "_coef": coef,
                        "_lower": conf[0],
                        "_upper": conf[1],
                        "_p_val": p_val,
                        "_name": target_coef_name,
                        "_std": target_std  # GÃ¶rsel Ã¶lÃ§ekleme iÃ§in
                    })
            
            progress_bar.empty()

            if summary_data:
                # --- TABLO ---
                df_res = pd.DataFrame(summary_data)
                display_cols = ["Parametre", "Adjusted Beta (Grup)", "%95 GA", "p"]
                
                st.subheader("ğŸ“Š Multivariate Regression Summary")
                st.caption(f"**Adjusted for:** {', '.join(confounders)}")
                st.table(df_res[display_cols])
                
                # --- FOREST PLOT ---
                st.markdown("---")
                st.subheader("ğŸ“ˆ Forest Plot: Etki KarÅŸÄ±laÅŸtÄ±rmasÄ±")
                
                # SEÃ‡ENEK: Standardizasyon
                use_std = st.checkbox("âœ… GrafiÄŸi Standardize Et (GÃ¶rsel Ä°yileÅŸtirme)", value=True, 
                                      help="FarklÄ± birimlerdeki (Ã–rn: SII vs NLR) deÄŸiÅŸkenleri aynÄ± Ã¶lÃ§eÄŸe getirir. Gri Ã§izgilerin gÃ¶rÃ¼nmesini saÄŸlar.")
                
                if use_std:
                    st.info("ğŸ’¡ **Bilgi:** DeÄŸerler standart sapmalarÄ±na bÃ¶lÃ¼nerek **'Standardized Beta'**ya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼. Bu sayede kÃ¼Ã§Ã¼k deÄŸerler (NLR) ile bÃ¼yÃ¼k deÄŸerler (SII) aynÄ± grafikte net gÃ¶rÃ¼lÃ¼r.")
                
                # Grafik Verisi
                plot_df = df_res.iloc[::-1]
                
                fig, ax = plt.subplots(figsize=(8, len(plot_df)*0.8 + 2))
                y_pos = range(len(plot_df))
                
                # MANUEL DÃ–NGÃœ (HatasÄ±z Ã‡izim)
                for i, (idx, row) in enumerate(plot_df.iterrows()):
                    # Verileri Ã‡ek
                    val_coef = row["_coef"]
                    val_low = row["_lower"]
                    val_high = row["_upper"]
                    
                    # EÄŸer Standardizasyon SeÃ§ildiyse:
                    if use_std:
                        s = row["_std"]
                        val_coef /= s
                        val_low /= s
                        val_high /= s
                    
                    # Renk SeÃ§imi
                    c = 'firebrick' if row["_p_val"] < 0.05 else 'gray'
                    # AnlamsÄ±z olanlarÄ± biraz daha soluk yapalÄ±m ki karÄ±ÅŸmasÄ±n
                    alpha_line = 1.0 if row["_p_val"] < 0.05 else 0.5
                    
                    # 1. Ã‡izgi
                    ax.hlines(y=i, xmin=val_low, xmax=val_high, 
                              color=c, linewidth=2, alpha=alpha_line, zorder=1)
                    
                    # 2. Nokta
                    ax.plot(val_coef, i, 'o', 
                            color=c, markersize=8, markeredgecolor='black', zorder=2)

                # 0 Referans Ã‡izgisi
                ax.axvline(x=0, color='black', linestyle='--', linewidth=1, zorder=0)
                
                # Eksenler
                ax.set_yticks(y_pos)
                ax.set_yticklabels(plot_df["Parametre"], fontweight="bold", fontsize=10)
                
                xlabel = "Standardized Beta (Etki GÃ¼cÃ¼)" if use_std else f"Raw Adjusted Beta ({summary_data[0]['_name']})"
                ax.set_xlabel(xlabel, fontweight="bold")
                
                # Grid ve Temizlik
                ax.grid(axis='x', linestyle=':', alpha=0.5)
                ax.spines['top'].set_visible(False)
                ax.spines['right'].set_visible(False)
                
                st.pyplot(fig)

            else:
                st.error("Model kurulamadÄ±.")
